{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04_training_NeuralNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7iP7f9HATtLiS9+apbw+x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/junyoung44/DL-fromScratch/blob/main/04_training_NeuralNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1617mvMdDUu"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def print_loss(func):\n",
        "  t=np.array([0,0,1,0,0,0,0,0,0,0])\n",
        "  y=np.array([0.1,0.05,0.6,0.0,0.05,0.1,0.0,0.1,0.0,0.0])\n",
        "\n",
        "  print(func(y,t))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oLtnUlpuHh4"
      },
      "source": [
        "# 4장 신경망 학습\n",
        "\n",
        "---\n",
        "\n",
        "  \n",
        "\n",
        "- 딥러닝은 end-to-end machine learning이다.\n",
        "\n",
        "- training data와 test data로 분리\n",
        "\n",
        "- overfitting 주의!\n",
        "\n",
        "  \n",
        "\n",
        "## Loss function\n",
        "\n",
        "----\n",
        "\n",
        "- 손실 함수의 목표는 손실을 최소화하는 weight를 찾기 위함이다.\n",
        "- 정확도를 사용하지 않는 이유\n",
        "  - weight의 미분이 대부분의 장소에서 0이 된다.\n",
        "  - weight의 미세한 변화에는 반응을 보이지 않는다,\n",
        "  - 반응을 보이더라도 값이 불연속적으로 갑작스레 변한다.\n",
        "\n",
        "### 1. 오차제곱합 (sum of squares for error: SSE)\n",
        "![enter image description here](https://datavedas.com/wp-content/uploads/2018/04/image001-1.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXd0Un3ryEO0",
        "outputId": "3046234b-c2aa-442e-fcee-6896cd6b2b94"
      },
      "source": [
        "def SSE(y,t):\n",
        "  return np.sum((y-t)**2)\n",
        "\n",
        "print_loss(SSE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.19500000000000006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m8_s9PQWa4Q"
      },
      "source": [
        "### 2. 교차 엔트로피 오차 (Cross Entropy Error : CEE)\n",
        "![enter image description here](https://blog.kakaocdn.net/dn/MEkru/btqBj6YVysE/NH7cfq6VThkB65mkfTlblK/img.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtX86VM-XOLN",
        "outputId": "f4e838e4-2f73-4dbc-e920-7be617105eff"
      },
      "source": [
        "def CEE(y,t):\n",
        "  delta=1e-7 # log(0)이 나오지 않게!\n",
        "  return -np.sum(t*np.log(y+delta))\n",
        "\n",
        "print_loss(CEE)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.510825457099338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YCvEB04mH9P"
      },
      "source": [
        "## Gradient descent\n",
        "---\n",
        "\n",
        "- learning rate가 너무 작으면 학습에 시간이 오래 걸림\n",
        "- learning rate가 너무 크면 발산함함"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "GLg3n2FJt8Zc",
        "outputId": "bae4cb6b-b364-400b-ed04-5bcbdef3b33c"
      },
      "source": [
        "def gradient_descent(f,init_x, lr=0.01, step_num=100):\n",
        "  x=init_x\n",
        "\n",
        "  for i in range(stemp_num):\n",
        "    grad=numercial_gradient(f,x)\n",
        "    x-=lr*grad\n",
        "  return x"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-eeed7a23b2a7>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    for i in range\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK5Sf0Y9kwQa"
      },
      "source": [
        "### Stochastic Gradient descent\n",
        "---\n",
        "\n",
        "#### Mini Batch\n",
        "\n",
        "- 모든 데이터를 대상으로 하려면 시간이 많이 걸린다.\n",
        "- 따라서 train data 중 일부를 뽑아내서 학습\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GX4ZnztvNGb"
      },
      "source": [
        "train_size=x_train.shape[0]\n",
        "batch_size=10\n",
        "batch_mask=np.random.choice(train_size, batch_size)\n",
        "\n",
        "x_batch=x_train[batch_mask]\n",
        "t_batch=t_train[batch_mask]"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}